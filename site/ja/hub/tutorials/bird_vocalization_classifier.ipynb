{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD3FvutQsaqc"
      },
      "source": [
        "##### Copyright 2023 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5fm9kVRsfuG"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2023 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNDQZiSGtXMu"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <!-- <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/bird_vocalization_classifier\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td> -->\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/bird_vocalization_classifier.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab で実行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/bird_vocalization_classifier.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub で表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/bird_vocalization_classifier.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "  <td><a href=\"https://tfhub.dev/google/bird-vocalization-classifier/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">TF Hub モデルを参照</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JAO_rv_QEBr"
      },
      "source": [
        "# Google Bird Vocalization モデルの使用\n",
        "\n",
        "Google Bird Vocalization は、グローバルな鳥類の埋め込みと分類モデルです。\n",
        "\n",
        "このモデルは、入力として、32kHz でサンプリングされた 5 秒間の音声セグメントを期待します。\n",
        "\n",
        "モデルは、音声の入力ウィンドウごとにロジットと埋め込みの両方を出力します。\n",
        "\n",
        "このノートブックでは、モデルに音声を適切にフィードする方法と推論にロジットを使用する方法について学習します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bytIYq0MjEKT"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"tensorflow_io==0.28.*\"\n",
        "!pip install -q librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXXTdq-eq6lk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "import csv\n",
        "import io\n",
        "\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mFpgMWQjgk"
      },
      "source": [
        "TFHub からのモデルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ1P3IkpQiya"
      },
      "outputs": [],
      "source": [
        "model_handle = \"https://tfhub.dev/google/bird-vocalization-classifier/1\"\n",
        "model = hub.load(model_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OOw23B3fZT6"
      },
      "source": [
        "モデルをトレーニングしたラベルを読み込みましょう。\n",
        "\n",
        "labels ファイルは、assets フォルダの labe.cvs にあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5i-R4k9ZhwN"
      },
      "outputs": [],
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "  with open(labels_path) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    class_names = [mid for mid, desc in csv_reader]\n",
        "    return class_names[1:]\n",
        "\n",
        "labels_path = hub.resolve(model_handle) + \"/assets/label.csv\"\n",
        "classes = class_names_from_csv(labels_path)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2JYPafeRRi_"
      },
      "source": [
        "`frame_audio` 関数は [Chirp ライブラリ](https://github.com/google-research/chirp/blob/10c5faa325a3c3468fa6f18a736fc1aeb9bf8129/chirp/inference/interface.py#L128) バージョンを基盤としていますが、librosa の代わりに tf.signal を使用しています。\n",
        "\n",
        "`ensure_sample_rate` は、モデルに使用される音声に、期待される 32kHzのサンプリングレートが使用されていることを確認する関数です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t65gi_DTrRaa"
      },
      "outputs": [],
      "source": [
        "def frame_audio(\n",
        "      audio_array: np.ndarray,\n",
        "      window_size_s: float = 5.0,\n",
        "      hop_size_s: float = 5.0,\n",
        "      sample_rate = 32000,\n",
        "  ) -> np.ndarray:\n",
        "    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "      return audio_array[np.newaxis, :]\n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
        "    return framed_audio\n",
        "\n",
        "def ensure_sample_rate(waveform, original_sample_rate,\n",
        "                       desired_sample_rate=32000):\n",
        "  \"\"\"Resample waveform if required.\"\"\"\n",
        "  if original_sample_rate != desired_sample_rate:\n",
        "    waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n",
        "  return desired_sample_rate, waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7uAuI4f6ehb"
      },
      "source": [
        "Wikipedia からファイルを読み込んでみましょう。\n",
        "\n",
        "より正確には、[クロウタドリ](https://es.wikipedia.org/wiki/Turdus_merula)の音声です。\n",
        "\n",
        "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Common_Blackbird.jpg/1200px-Common_Blackbird.jpg\" alt=\"Common Blackbird.jpg\" class=\"\"></p>\n",
        ":-:\n",
        "*By <a rel=\"nofollow\" class=\"external text\" href=\"http://photo-natur.de\">Andreas Trepte</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/2.5\" title=\"Creative Commons Attribution-Share Alike 2.5\">CC BY-SA 2.5</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=16110223\">Link</a>*\n",
        "\n",
        "この音声はパブリックドメインライセンスの下、Oona Räisänen (Mysid) によって貢献されたものです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whkmGeJ9lmyd"
      },
      "outputs": [],
      "source": [
        "!curl -O  \"https://upload.wikimedia.org/wikipedia/commons/7/7c/Turdus_merula_2.ogg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff6nOV2EurAO"
      },
      "outputs": [],
      "source": [
        "turdus_merula = \"Turdus_merula_2.ogg\"\n",
        "\n",
        "audio, sample_rate = librosa.load(turdus_merula)\n",
        "\n",
        "sample_rate, wav_data_turdus = ensure_sample_rate(audio, sample_rate)\n",
        "Audio(wav_data_turdus, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjpKLk9K7TTV"
      },
      "source": [
        "音声は 24 秒で、モデルは 5 秒を期待しています。\n",
        "\n",
        "これは、`frame_audio` 関数を使って修正し、適切なフレームに音声を分割できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzgK0xWw9g8X"
      },
      "outputs": [],
      "source": [
        "fixed_tm = frame_audio(wav_data_turdus)\n",
        "fixed_tm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU5-UqaCAVZ7"
      },
      "source": [
        "では、最初のフレームにモデルを適用してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zveWSOU9QBC"
      },
      "outputs": [],
      "source": [
        "logits, embeddings = model.infer_tf(fixed_tm[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osmRNWciEEuG"
      },
      "source": [
        "label.csv ファイルには、ebirds id が含まれています。Turdus Merula（クロウタドリツグミ）の ebird id は eurbla です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-UehjA6Acn_"
      },
      "outputs": [],
      "source": [
        "probabilities = tf.nn.softmax(logits)\n",
        "argmax = np.argmax(probabilities)\n",
        "print(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGK84egXBg2f"
      },
      "source": [
        "では、すべてのフレームにモデルを適用してみましょう。\n",
        "\n",
        "*注意*: このコードも [Chirp ライブラリ](https://github.com/google-research/chirp/blob/d6ff5e7cee3865940f31697bf4b70176c1072572/chirp/inference/models.py#L174)に基づいています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT_Im9i50EGy"
      },
      "outputs": [],
      "source": [
        "all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n",
        "for window in fixed_tm[1:]:\n",
        "  logits, embeddings = model.infer_tf(window[np.newaxis, :])\n",
        "  all_logits = np.concatenate([all_logits, logits], axis=0)\n",
        "\n",
        "all_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKuJWq4SxyR1"
      },
      "outputs": [],
      "source": [
        "frame = 0\n",
        "for frame_logits in all_logits:\n",
        "  probabilities = tf.nn.softmax(frame_logits)\n",
        "  argmax = np.argmax(probabilities)\n",
        "  print(f\"For frame {frame}, the audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[argmax]}\")\n",
        "  frame += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bird_vocalization_classifier.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
